{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pyvene.models.configuration_intervenable_model import RepresentationConfig, IntervenableConfig\n",
    "from pyvene.models.intervenable_base import IntervenableModel\n",
    "from pyvene.models.interventions import BoundlessRotatedSpaceIntervention\n",
    "from pyvene.models.basic_utils import set_seed, count_parameters\n",
    "\n",
    "\n",
    "from utils.prompt_utils import *\n",
    "from utils.intervention_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.eval_utils import *\n",
    "from utils.extract_utils import *\n",
    "from utils.das_utils import *\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  /data/public_models/mistral/mistral-7b-instruct-v0.1\n",
      "/data/public_models/mistral/mistral-7b-instruct-v0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1105e3ab6d164d8b85a149d12da72fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jiuding_sun/miniconda3/envs/fv/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, model_config = load_gpt_model_and_tokenizer(\"/data/public_models/mistral/mistral-7b-instruct-v0.1\", device=\"cuda\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def intervention_collate_fn(batch):\n",
    "    base_input_ids, base_labels, source_input_ids, source_labels, source_predictive_token_idxs, predictive_token_idxs = tuple(\n",
    "        [data_pair[key] for data_pair in batch] for key in \n",
    "        ('base_input_ids', 'base_labels', 'source_input_ids', 'source_labels', 'source_predictive_token_idxs', 'predictive_token_idxs')\n",
    "    )\n",
    "    \n",
    "    base_input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        base_input_ids, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    source_input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "        source_input_ids, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    base_labels = torch.nn.utils.rnn.pad_sequence(base_labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "    source_labels = torch.nn.utils.rnn.pad_sequence(source_labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "    \n",
    "    source_predictive_token_idxs = torch.LongTensor(source_predictive_token_idxs)\n",
    "    predictive_token_idxs = torch.LongTensor(predictive_token_idxs)\n",
    "    \n",
    "    return dict(\n",
    "        base_input_ids=base_input_ids,\n",
    "        base_labels=base_labels,\n",
    "        base_attention_mask=base_input_ids.ne(tokenizer.pad_token_id),\n",
    "        source_input_ids=source_input_ids,\n",
    "        source_labels=source_labels,\n",
    "        source_attention_mask=source_input_ids.ne(tokenizer.pad_token_id),\n",
    "        predictive_token_idxs=predictive_token_idxs,\n",
    "        source_predictive_token_idxs=source_predictive_token_idxs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervenable_config = simple_boundless_das_position_config(type(model), \"block_output\", 15)\n",
    "intervenable = IntervenableModel(intervenable_config, model)\n",
    "intervenable.set_device(\"cuda\")\n",
    "intervenable.disable_model_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['park-country', 'person-sport', 'lowercase_first_letter', 'landmark-country', 'national_parks', 'person-instrument', 'product-company', 'prev_item', 'synonym', 'english-spanish', 'country-currency', 'capitalize_first_letter', 'next_item', 'person-occupation', 'english-german', 'lowercase_last_letter']\n"
     ]
    }
   ],
   "source": [
    "HELD_IN_DATASETS = [f.replace(\".json\", \"\") for f in  os.listdir(\"../dataset_files/abstractive\") if f not in \n",
    "                    [\"antonym.json\", \"capitalize.json\", \"present-past.json\", \n",
    "                     \"english-french.json\", \"singular-plural.json\", \"country-capital.json\", \n",
    "                     \"ag_news.json\", \"commonsense_qa.json\", \"sentiment.json\"]]\n",
    "\n",
    "print(HELD_IN_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "prefixes = {\"input\": \"Word:\", \"output\": \"Letter:\", \"instructions\": \"What is the first lowercase letter in the input?\"}\n",
    "separators = {\"input\":\"\\n\", \"output\":\"\\n\\n\", \"instructions\":\"\\n\\n\"}\n",
    "dataset_name = \"lowercase_last_letter\"\n",
    "\n",
    "dataset = load_dataset(dataset_name, root_data_dir=\"../dataset_files\", test_size=0.3, seed=42)\n",
    "\n",
    "eval_no_intervention_dataloader = process_dataloader(dataset, model_config, tokenizer, 16, 0, \"valid\", prefixes, separators, intervention_collate_fn, ablation_method=\"zero_shot\")\n",
    "eval_dict = evaluate(intervenable, eval_no_intervention_dataloader, device=model.device, intervene=False, corrupt=False, generate_output=True)\n",
    "print(f\"[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: {eval_dict['accuracy']}\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'i', 'o', 'f', 'o', 't', 'n', 'u', 'o', 't']\n",
      "['e', 'e', 'h', 'l', 'k', 't', 't', 'l', 'g', 't']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.decode(eval_dict[\"outputs\"][i]) for i in range(10)])\n",
    "print([tokenizer.decode(eval_dict[\"labels\"][i]) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_template_information():\n",
    "    root_dir = f\"../template_files/{dataset_name}\"\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "    \n",
    "    all_templates = os.listdir(root_dir)\n",
    "    \n",
    "    all_templates = [int(template) for template in all_templates]\n",
    "    next_template = max(all_templates) + 1 if len(all_templates) > 0 else 1\n",
    "    \n",
    "    os.makedirs(f\"{root_dir}/{next_template}\")\n",
    "    json.dump(prefixes, open(f\"{root_dir}/{next_template}/prefixes.json\", \"w\"))\n",
    "    json.dump(separators, open(f\"{root_dir}/{next_template}/separators.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_template_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
