{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from nnsight_DAS_utils import *\n",
    "\n",
    "from utils.prompt_utils import *\n",
    "from utils.intervention_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.eval_utils import *\n",
    "from utils.extract_utils import *\n",
    "import seaborn as sns\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "# from utils.das_utils import *\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "HELD_IN_DATASETS = [f.replace(\".json\", \"\") for f in  os.listdir(\"../dataset_files/abstractive\") if f not in \n",
    "                    [\"antonym.json\", \"capitalize.json\", \"present-past.json\", \n",
    "                     \"english-french.json\", \"singular-plural.json\", \"country-capital.json\", \n",
    "                     \"ag_news.json\", \"commonsense_qa.json\", \"sentiment.json\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"antonym\"]\n",
    "ie_path = \"../results/AIE/ICL/flan-llama-7b/held_in_tasks/held_in_tasks_indirect_effect.pt\"\n",
    "model_name = \"/work/frink/models/flan-llama-7b\"\n",
    "\n",
    "root_data_dir = \"../dataset_files\"\n",
    "seed = 42\n",
    "device = \"cuda\"\n",
    "\n",
    "test_split = 0.3\n",
    "n_shots = 10\n",
    "n_trials = 512\n",
    "\n",
    "\n",
    "prefixes = load_prefixes_or_separators({\"input\":\"Q:\", \"output\":\"A:\", \"instructions\":\"\"})\n",
    "separators = load_prefixes_or_separators({\"input\":\"\\n\", \"output\":\"\\n\\n\", \"instructions\":\"\"})\n",
    "\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "epochs = 10\n",
    "warmup_ratio = 0.1\n",
    "rotate_lr = 1e-3\n",
    "boundary_lr = 1e-2\n",
    "dimension_weights = 1.5\n",
    "\n",
    "temperature_start = 50.0\n",
    "temperature_end = 0.1\n",
    "\n",
    "evaluate_per_epoch = False\n",
    "training_method = \"zero_shot\"\n",
    "generate_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e921d7016a84a84828b01e248e19eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, model_config = load_nnsight_model(model_name=model_name, device=device)\n",
    "set_requires_grad(model, False)\n",
    "\n",
    "\n",
    "att_head_dim = model_config[\"resid_dim\"] // model_config[\"n_heads\"]\n",
    "top_heads = load_top_k_aie(ie_path, k=10)\n",
    "\n",
    "intervention_projections = dict()\n",
    "for layer, idx, _ in top_heads:\n",
    "    head_projection = BoundlessRotatedSpaceIntervention(att_head_dim).to('cuda')\n",
    "    head_projection.rotate_layer.weight = torch.eye(att_head_dim).to('cuda')\n",
    "    \n",
    "    if layer not in intervention_projections.keys():\n",
    "        intervention_projections[layer] = dict()\n",
    "    \n",
    "    intervention_projections[layer][idx] = head_projection\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        \n",
    "# Load the dataset\n",
    "print(\"Loading Dataset\")\n",
    "set_seed(seed)\n",
    "datasets = [load_dataset(dataset_name, root_data_dir=root_data_dir, test_size=test_split, seed=seed) for dataset_name in dataset_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_no_intervention_dataloader = process_mixed_dataloader(datasets, model_config, tokenizer, batch_size, n_shots, \"valid\", prefixes, separators, intervention_collate_fn(tokenizer), ablation_method=\"zero_shot\", draw_source_from_split=True)\n",
    "train_dataloader = process_mixed_dataloader(datasets, model_config, tokenizer, batch_size, n_shots, \"train\", prefixes, separators, intervention_collate_fn(tokenizer), n_trials=n_trials, ablation_method=training_method, draw_source_from_split=False)\n",
    "\n",
    "fs_eval_dataloader = process_mixed_dataloader(datasets, model_config, tokenizer, batch_size, n_shots, \"valid\", prefixes, separators, intervention_collate_fn(tokenizer), ablation_method=\"noninformative\", draw_source_from_split=True)\n",
    "zs_eval_dataloader = process_mixed_dataloader(datasets, model_config, tokenizer, batch_size, n_shots, \"valid\", prefixes, separators, intervention_collate_fn(tokenizer), ablation_method=\"zero_shot\", draw_source_from_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subspace_proj trainable parameters:  163860\n"
     ]
    }
   ],
   "source": [
    "t_total = int(len(train_dataloader) * epochs)\n",
    "warm_up_steps = 0.1 * t_total\n",
    "\n",
    "target_total_step = len(train_dataloader) * epochs\n",
    "\n",
    "temperature_schedule = torch.linspace(\n",
    "    temperature_start, temperature_end, target_total_step\n",
    ").to(torch.bfloat16).to(device)\n",
    "\n",
    "# Define params to be learned\n",
    "optimizer_params = []\n",
    "param_count = 0\n",
    "total_step = 0\n",
    "\n",
    "for layer in intervention_projections.keys():\n",
    "    for idx in intervention_projections[layer].keys():\n",
    "        optimizer_params += [{'params': intervention_projections[layer][idx].rotate_layer.parameters()}]\n",
    "        optimizer_params += [{'params': intervention_projections[layer][idx].intervention_boundaries, 'lr': boundary_lr}]\n",
    "        \n",
    "        param_count += count_parameters(intervention_projections[layer][idx])\n",
    "        intervention_projections[layer][idx].set_temperature(temperature_schedule[total_step])\n",
    "        intervention_projections[layer][idx].train()\n",
    "        \n",
    "optimizer = torch.optim.Adam(\n",
    "    optimizer_params,\n",
    "    lr=rotate_lr,\n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warm_up_steps,\n",
    "    num_training_steps=t_total\n",
    ")\n",
    "\n",
    "print(\"subspace_proj trainable parameters: \", param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_subspace_swap_by_attentions(batch, model:nnsight.LanguageModel, subspace_projs): #, batch_size=16\n",
    "    \"\"\"\n",
    "    Batched subspace_swap intervention at a single layer using nnsight\n",
    "    \"\"\"\n",
    "    batch_size = len(batch['base_input_ids'])\n",
    "    all_inds = torch.arange(batch_size)\n",
    "        \n",
    "    base_prompt, source_prompt = batch['base_input_ids'][:batch_size], batch['source_input_ids'][:batch_size]\n",
    "    base_intervention_token_idx, source_intervention_token_idx = batch['base_predictive_token_idxs'][:batch_size], batch['source_predictive_token_idxs'][:batch_size]\n",
    "    \n",
    "    bases, sources = [], []\n",
    "    layers, idxs = [], []\n",
    "    \n",
    "    all_layers = sorted(list(subspace_projs.keys()))\n",
    "\n",
    "    for layer in all_layers:\n",
    "        for idx in subspace_projs[layer]:\n",
    "            layers.append(layer)\n",
    "            idxs.append(idx)\n",
    "            \n",
    "            start_dim_idx = idx * att_head_dim\n",
    "            end_dim_idx = (idx + 1) * att_head_dim\n",
    "            \n",
    "            with model.trace(validate=False) as tracer:\n",
    "                with tracer.invoke(base_prompt, scan=False):\n",
    "                    base = model.model.layers[layer].self_attn.o_proj.input[0][0][all_inds, :, start_dim_idx:end_dim_idx].save()\n",
    "                    bases.append(base)\n",
    "                \n",
    "                with tracer.invoke(source_prompt, scan=False):\n",
    "                    source = model.model.layers[layer].self_attn.o_proj.input[0][0][all_inds, :, start_dim_idx:end_dim_idx].save()\n",
    "                    sources.append(source)                    \n",
    "\n",
    "    with model.trace(validate=False) as tracer:\n",
    "        # intervention\n",
    "        with tracer.invoke(base_prompt, scan=False):\n",
    "            for layer, idx, base, source in zip(layers, idxs, bases, sources):\n",
    "                \n",
    "                subspace_proj = subspace_projs[layer][idx]\n",
    "                \n",
    "                B = base[all_inds,base_intervention_token_idx, :]\n",
    "                S = source[all_inds,source_intervention_token_idx, :]\n",
    "\n",
    "                mixed_out = subspace_proj(B, S, batch_size)\n",
    "                model.model.layers[layer].self_attn.o_proj.input[0][0][all_inds, base_intervention_token_idx, start_dim_idx: end_dim_idx] = mixed_out\n",
    "                del base, source, B,S\n",
    "                \n",
    "        save_out = model.output.save()\n",
    "    \n",
    "    \n",
    "    output_logits = save_out.value.logits\n",
    "    del save_out\n",
    "    return output_logits\n",
    "\n",
    "\n",
    "def evaluate_w_subspace_intervention_by_attentions(model, subspace_projs, dataloader, device=\"cuda\", generate_output=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        eval_labels = []\n",
    "        eval_preds = []\n",
    "        \n",
    "        for step, inputs in enumerate(tqdm(dataloader)):\n",
    "            for k, v in inputs.items():\n",
    "                if v is not None and isinstance(v, torch.Tensor):\n",
    "                    inputs[k] = v.to(device)\n",
    "\n",
    "            outputs = batch_subspace_swap_by_attentions(inputs, model, subspace_projs)#, batch_size=dataloader.batch_size)\n",
    "            eval_labels += [inputs['base_labels'].detach().cpu()]\n",
    "                \n",
    "            eval_preds += [outputs.detach().cpu()]\n",
    "        \n",
    "        eval_metrics = compute_metrics(eval_preds, eval_labels, generate_output=generate_output)\n",
    "        return eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [15:36<00:00, 34.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "zs_intervention_acc = evaluate_w_subspace_intervention_by_attentions(model, intervention_projections, zs_eval_dataloader, device=model.device, generate_output=generate_output)\n",
    "print(zs_intervention_acc)   \n",
    "zs_no_intervention_acc = evaluate_no_intervention(model, zs_eval_dataloader, device=model.device, corrupt=True, generate_output=generate_output)\n",
    "print(zs_no_intervention_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
